{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20200707_Test_Model_4_csv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNs5UnbOv+ttbSXYHFtNJm/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NgaAdrain/TEAM_Enter_Text_Here/blob/master/Data_Varification/20200707_Test_Model_4_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-NCX5rWCyl-",
        "colab_type": "text"
      },
      "source": [
        "csv -> data<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WX_DRl9CtMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "913bf1c5-6386-4195-cc57-75c7bf58d4cd"
      },
      "source": [
        "# Import the TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "tf.__version__\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7P-ZqswH1Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WINDOW_SIZE = 32\n",
        "data_file = pd.read_csv('/content/20200707_161530.csv',encoding='utf-8')\n",
        "data_file.drop(['Timestamp'],axis = 'columns',inplace=True)\n",
        "#print(data_file)\n",
        "#for d in data_file:\n",
        "#  print(data_file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmYlV4k7IDz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = data_file.pop('Label')\n",
        "#list(data_file.values)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aheIkoks8gu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = pd.read_csv('/content/20200707_160439.csv',encoding='utf-8')\n",
        "train_file.RPM = train_file.RPM/5000\n",
        "train_file.Velocity = train_file.Velocity/200\n",
        "train_file.drop(['Timestamp'],axis = 'columns',inplace=True)\n",
        "train_file_label = train_file.pop('Label1')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JaQlnhp9LQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_array = np.delete(train_file.values,-1,0)\n",
        "train_label = np.delete(train_file_label.values,-1,0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alxn8UQZ8ykK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file = pd.read_csv('/content/20200707_164523.csv',encoding='utf-8')\n",
        "test_file.drop(['Label1'],axis = 'columns',inplace=True)\n",
        "test_file.RPM = test_file.RPM/5000\n",
        "test_file.Velocity = test_file.Velocity/200\n",
        "test_file_timestamp = test_file.pop('Timestamp')\n",
        "test_array = np.delete(test_file.values,-1,0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWC9XGlj9gbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "475b07f1-c364-4e62-e9d3-7903cd2b908b"
      },
      "source": [
        "xdataset = []\n",
        "ydataset = []\n",
        "#in range()\n",
        "for i in range(WINDOW_SIZE, train_array.shape[0] + 1, 1):\n",
        "  xdataset.append(train_array[i-WINDOW_SIZE:i])\n",
        "  ydataset.append(train_label[i-1])\n",
        "xtrain = np.array(xdataset) #32개의 데이터를 1개의 window 단위로 설정\n",
        "ytrain = np.array(ydataset) #각 window의 마지막 원소를 대표 label로 지정\n",
        "print(xtrain.shape)\n",
        "print(ytrain.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6149, 32, 7)\n",
            "(6149,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8UgkY8W9xwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5d0cc5a7-e26f-4747-a94a-709c8e2ea8dd"
      },
      "source": [
        "xdataset = []\n",
        "ydataset = []\n",
        "#in range()\n",
        "for i in range(WINDOW_SIZE, test_array.shape[0] + 1, 1):\n",
        "  xdataset.append(test_array[i-WINDOW_SIZE:i])\n",
        "  ydataset.append(0)\n",
        "xtest = np.array(xdataset) #32개의 데이터를 1개의 window 단위로 설정\n",
        "ytest = np.array(ydataset)\n",
        "print(xtest.shape)\n",
        "print(ytest.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17867, 32, 7)\n",
            "(17867,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF2fV7y-XovZ",
        "colab_type": "text"
      },
      "source": [
        "모든 value가 0\\~1사이(또는 -1~1 사이)의 값이 되도록 나누기(정규화 과정)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7l2s4or1Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_file.RPM = data_file.RPM/5000\n",
        "data_file.Velocity = data_file.Velocity/200"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpqAgMR9r45m",
        "colab_type": "text"
      },
      "source": [
        "test_dataset의 sliding window를 정하기 ex) 32 -> 2차원을 3차원으로"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG3I_FMxaGIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "44bddc71-699e-469a-88a3-e6748c68be55"
      },
      "source": [
        "print(type(data_file))\n",
        "print(type(data_file.values))\n",
        "np_array = np.delete(data_file.values,-1,0)\n",
        "label = np.delete(label.values,-1,0)\n",
        "print(type(np_array))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGlv41ySMNsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0bcb40af-0eb9-46e3-c5ea-3a47ac54dc17"
      },
      "source": [
        "xdataset = []\n",
        "ydataset = []\n",
        "#in range()\n",
        "for i in range(WINDOW_SIZE, np_array.shape[0] + 1, 1):\n",
        "  xdataset.append(np_array[i-WINDOW_SIZE:i])\n",
        "  ydataset.append(label[i-1])\n",
        "np_xtest = np.array(xdataset) #32개의 데이터를 1개의 window 단위로 설정\n",
        "np_ytest = np.array(ydataset) #각 window의 마지막 원소를 대표 label로 지정\n",
        "print(np_xtest.shape)\n",
        "print(np_ytest.shape)\n",
        "#test_dataset = tf.data.Dataset.from_tensor_slices((data_file.values, label.values))\n",
        "#print(type(data_file.values[0]))\n",
        "#print(type(test_dataset))\n",
        "#test_dataset = test_dataset.window(32,shift=1)\n",
        "#data_file.values.shape\n",
        "#for ds in test_dataset:\n",
        "#  print(ds)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2906, 32, 7)\n",
            "(2906,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnaJZ7roMbH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for val, lab in test_dataset.take(40):\n",
        "#  print('Values: {}, Label: {}'.format(val,lab))\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(32, 7)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWvWQ9mF6oNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "dd314a9a-6cc5-412b-b8f2-437c9e11c2f7"
      },
      "source": [
        "model.fit(np_xtest, np_ytest, epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9446\n",
            "Epoch 2/5\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9900\n",
            "Epoch 3/5\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9945\n",
            "Epoch 4/5\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9962\n",
            "Epoch 5/5\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feeddb7a208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4cidSt99ZvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "6e7dcd67-016e-4126-dbba-a55d63e81d9f"
      },
      "source": [
        "model.fit(xtrain, ytrain, epochs=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "193/193 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9950\n",
            "Epoch 2/5\n",
            "193/193 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 0.9987\n",
            "Epoch 3/5\n",
            "193/193 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9993\n",
            "Epoch 4/5\n",
            "193/193 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "193/193 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feed4824550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzWDlEzn_FK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0814c755-811a-4dc5-d7d0-5624acef623b"
      },
      "source": [
        "#test_loss, test_acc = model.evaluate(xtest,  ytest, verbose=2)\n",
        "predictions = model.predict(xtest)\n",
        "count = 0\n",
        "print(type(test_file_timestamp[0]))\n",
        "txt = 'Timestamp,Direction\\n'\n",
        "for temp in xtest:\n",
        "  #print(test_file_timestamp[count],end=' ')\n",
        "  txt = txt + ',' + test_file_timestamp[count] + ' '\n",
        "  if(np.argmax(predictions[count]) == 0):\n",
        "  #  print('straight')\n",
        "    txt = txt + ',straight\\n'\n",
        "  elif(np.argmax(predictions[count]) == 1):\n",
        "  #  print('left')\n",
        "    txt = txt + ',left\\n'\n",
        "  else:\n",
        "    txt = txt + ',right\\n'\n",
        "  #  print('right')\n",
        "  count = count + 1\n",
        "\n",
        "f = open(\"test_output.csv\",'w')\n",
        "f.write(txt)\n",
        "f.close()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}